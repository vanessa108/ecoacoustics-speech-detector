{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\r\n",
    "import sys\r\n",
    "from IPython import display\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import csv\r\n",
    "from sklearn import metrics\r\n",
    "import tensorflow as tf\r\n",
    "import tensorflow_hub as hub\r\n",
    "import tensorflow_io as tfio"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import YAMNet\r\n",
    "There are two ways of doing this:\r\n",
    "* Downloading YAMNet from TensorFlow Hub\r\n",
    "* Downloading the full YAMNet repository, and loading in the pre-trained weights (offers customisability with hop length) "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Option 1: Download from TF Hub"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "yamnet_model_handle = 'https://tfhub.dev/google/yamnet/1'\r\n",
    "yamnet_model = hub.load(yamnet_model_handle)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Option 2: Download YAMNet repo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# !git clone https://github.com/tensorflow/models.\r\n",
    "# !wget https://storage.googleapis.com/audioset/yamnet.h5\r\n",
    "yamnet_dir = './models/research/audioset/yamnet/'\r\n",
    "sys.path.append(yamnet_dir)\r\n",
    "import params as yamnet_params\r\n",
    "import yamnet as yamnet\r\n",
    "import features as features_lib\r\n",
    "from tensorflow.keras import Model, layers\r\n",
    "from tensorflow.keras.optimizers import SGD, Adam\r\n",
    "from tensorflow.keras.callbacks import EarlyStopping\r\n",
    "from tensorflow import keras\r\n",
    "# test patch size of 0.32, 3 patches per window (96)\r\n",
    "params = yamnet_params.Params(patch_hop_seconds=0.32)\r\n",
    "og_class_names = yamnet.class_names('./models/research/audioset/yamnet/yamnet_class_map.csv')\r\n",
    "yamnet_model  = yamnet.yamnet_frames_model(params)\r\n",
    "yamnet_model.load_weights('yamnet.h5')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Utility Functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "@tf.function\r\n",
    "def load_wav_16k_mono(filename):\r\n",
    "    \"\"\" Load a WAV file, convert it to a float tensor, resample to 16 kHz single-channel audio. \"\"\"\r\n",
    "    file_contents = tf.io.read_file(filename)\r\n",
    "    wav, sample_rate = tf.audio.decode_wav(\r\n",
    "          file_contents,\r\n",
    "          desired_channels=1)\r\n",
    "    wav = tf.squeeze(wav, axis=-1)\r\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\r\n",
    "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\r\n",
    "    return wav\r\n",
    "def load_wav_for_map(filename, label):\r\n",
    "  return load_wav_16k_mono(filename), label\r\n",
    "  \r\n",
    "def extract_embedding(wav_data, label):\r\n",
    "  ''' run YAMNet to extract embedding from the wav data '''\r\n",
    "  scores, embeddings, spectrogram = yamnet_model(wav_data)\r\n",
    "  num_embeddings = tf.shape(embeddings)[0]\r\n",
    "  return (embeddings,\r\n",
    "            tf.repeat(label, num_embeddings))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import training and validation data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# load data from csv\r\n",
    "path = 'C:/Users/vanes/OneDrive - Queensland University of Technology/Sem 2 2021/EGH400-2/CV-files/cv-valid-train'\r\n",
    "cv_file_csv = path + '/cv_train_main_file.csv'\r\n",
    "train_data = pd.read_csv(cv_file_csv)\r\n",
    "\r\n",
    "val_data = pd.read_csv('C:/Users/vanes/OneDrive - Queensland University of Technology/Sem 2 2021/EGH400-2/CV-files/cv-valid-dev/cv_val_main_file.csv')\r\n",
    "\r\n",
    "# add directory paths to file names\r\n",
    "train_filenames = train_data['filename']\r\n",
    "filepath = path + '/cv-train-mix-chunks/'\r\n",
    "train_filenames = [filepath + f for f in train_filenames]\r\n",
    "train_targets = train_data['label']\r\n",
    "\r\n",
    "val_filenames = val_data['filename']\r\n",
    "val_filepath ='C:/Users/vanes/OneDrive - Queensland University of Technology/Sem 2 2021/EGH400-2/CV-files/cv-valid-dev/cv-dev-mix-chunks/'\r\n",
    "val_filenames = [val_filepath + f for f in val_filenames]\r\n",
    "val_targets = val_data['label']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((train_filenames, train_targets))\r\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((val_filenames, val_targets))\r\n",
    "\r\n",
    "# audio file to wav \r\n",
    "train_ds = train_ds.map(load_wav_for_map)\r\n",
    "val_ds = val_ds.map(load_wav_for_map)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extract YAMNet embeddings to prepare for training\r\n",
    "The dataset now contains WAV arrays with labels. Using YAMNet, the embeddings (n, 1024) will be used as features for the new speech detector layer. \r\n",
    "\r\n",
    "The default hop length is 0.48 seconds, meaning YAMnet will output a set of embeddings for each 0.48 seconds. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "train_ds = train_ds.map(extract_embedding).unbatch()\r\n",
    "val_ds = val_ds.map(extract_embedding).unbatch()\r\n",
    "train_ds = train_ds.cache().shuffle(1000).batch(32).prefetch(tf.data.AUTOTUNE)\r\n",
    "val_ds = val_ds.cache().batch(32).prefetch(tf.data.AUTOTUNE)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Defining and training the speech detector"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "my_classes = ['not speech', 'speech']\r\n",
    "map_class_to_id = {'not speech':0, 'speech':1}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "\r\n",
    "speech_model = tf.keras.Sequential([\r\n",
    "    tf.keras.layers.Input(shape=(1024), dtype=tf.float32, # YAMnet embeddings as input \r\n",
    "                          name='input_embedding'),\r\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\r\n",
    "    tf.keras.layers.Dense(len(my_classes)) \r\n",
    "], name='speech_model')\r\n",
    "\r\n",
    "speech_model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"speech_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 525,826\n",
      "Trainable params: 525,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "from tensorflow.keras.optimizers import SGD, Adam, Adamax\r\n",
    "#opt = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\r\n",
    "opt = Adamax(learning_rate=0.00001)\r\n",
    "speech_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n",
    "                 optimizer=opt,\r\n",
    "                 metrics=['accuracy'])\r\n",
    "\r\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss',\r\n",
    "                                            patience=3,\r\n",
    "                                            restore_best_weights=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "history = speech_model.fit(train_ds,\r\n",
    "                       epochs=500,\r\n",
    "                       validation_data=val_ds,\r\n",
    "                       callbacks=callback)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/500\n",
      "133/133 [==============================] - 16s 96ms/step - loss: 0.7109 - accuracy: 0.5045 - val_loss: 0.6803 - val_accuracy: 0.5864\n",
      "Epoch 2/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.6311 - accuracy: 0.7092 - val_loss: 0.6691 - val_accuracy: 0.6289\n",
      "Epoch 3/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5813 - accuracy: 0.7892 - val_loss: 0.6542 - val_accuracy: 0.6728\n",
      "Epoch 4/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5422 - accuracy: 0.8217 - val_loss: 0.6368 - val_accuracy: 0.7096\n",
      "Epoch 5/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.8394 - val_loss: 0.6179 - val_accuracy: 0.7295\n",
      "Epoch 6/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.8552 - val_loss: 0.5975 - val_accuracy: 0.7535\n",
      "Epoch 7/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.8675 - val_loss: 0.5782 - val_accuracy: 0.7663\n",
      "Epoch 8/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.8757 - val_loss: 0.5595 - val_accuracy: 0.7833\n",
      "Epoch 9/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.8868 - val_loss: 0.5398 - val_accuracy: 0.8003\n",
      "Epoch 10/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3897 - accuracy: 0.8939 - val_loss: 0.5226 - val_accuracy: 0.8045\n",
      "Epoch 11/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3719 - accuracy: 0.8981 - val_loss: 0.5074 - val_accuracy: 0.8074\n",
      "Epoch 12/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3554 - accuracy: 0.9024 - val_loss: 0.4926 - val_accuracy: 0.8102\n",
      "Epoch 13/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3404 - accuracy: 0.9094 - val_loss: 0.4782 - val_accuracy: 0.8144\n",
      "Epoch 14/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3264 - accuracy: 0.9130 - val_loss: 0.4661 - val_accuracy: 0.8187\n",
      "Epoch 15/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3140 - accuracy: 0.9149 - val_loss: 0.4540 - val_accuracy: 0.8272\n",
      "Epoch 16/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.3023 - accuracy: 0.9189 - val_loss: 0.4432 - val_accuracy: 0.8286\n",
      "Epoch 17/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2919 - accuracy: 0.9200 - val_loss: 0.4331 - val_accuracy: 0.8286\n",
      "Epoch 18/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2825 - accuracy: 0.9215 - val_loss: 0.4245 - val_accuracy: 0.8329\n",
      "Epoch 19/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2739 - accuracy: 0.9222 - val_loss: 0.4164 - val_accuracy: 0.8343\n",
      "Epoch 20/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2658 - accuracy: 0.9252 - val_loss: 0.4086 - val_accuracy: 0.8371\n",
      "Epoch 21/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2584 - accuracy: 0.9264 - val_loss: 0.4021 - val_accuracy: 0.8399\n",
      "Epoch 22/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2519 - accuracy: 0.9257 - val_loss: 0.3961 - val_accuracy: 0.8428\n",
      "Epoch 23/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.9271 - val_loss: 0.3901 - val_accuracy: 0.8470\n",
      "Epoch 24/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2400 - accuracy: 0.9281 - val_loss: 0.3849 - val_accuracy: 0.8470\n",
      "Epoch 25/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2345 - accuracy: 0.9295 - val_loss: 0.3799 - val_accuracy: 0.8470\n",
      "Epoch 26/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2295 - accuracy: 0.9295 - val_loss: 0.3751 - val_accuracy: 0.8484\n",
      "Epoch 27/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2248 - accuracy: 0.9309 - val_loss: 0.3707 - val_accuracy: 0.8484\n",
      "Epoch 28/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2206 - accuracy: 0.9300 - val_loss: 0.3665 - val_accuracy: 0.8499\n",
      "Epoch 29/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2165 - accuracy: 0.9318 - val_loss: 0.3624 - val_accuracy: 0.8499\n",
      "Epoch 30/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2127 - accuracy: 0.9323 - val_loss: 0.3584 - val_accuracy: 0.8499\n",
      "Epoch 31/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2092 - accuracy: 0.9330 - val_loss: 0.3552 - val_accuracy: 0.8527\n",
      "Epoch 32/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2060 - accuracy: 0.9330 - val_loss: 0.3521 - val_accuracy: 0.8527\n",
      "Epoch 33/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2032 - accuracy: 0.9335 - val_loss: 0.3492 - val_accuracy: 0.8555\n",
      "Epoch 34/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2002 - accuracy: 0.9351 - val_loss: 0.3458 - val_accuracy: 0.8569\n",
      "Epoch 35/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1977 - accuracy: 0.9356 - val_loss: 0.3430 - val_accuracy: 0.8584\n",
      "Epoch 36/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1954 - accuracy: 0.9358 - val_loss: 0.3407 - val_accuracy: 0.8598\n",
      "Epoch 37/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1930 - accuracy: 0.9358 - val_loss: 0.3384 - val_accuracy: 0.8612\n",
      "Epoch 38/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1909 - accuracy: 0.9361 - val_loss: 0.3366 - val_accuracy: 0.8584\n",
      "Epoch 39/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1889 - accuracy: 0.9366 - val_loss: 0.3345 - val_accuracy: 0.8612\n",
      "Epoch 40/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1870 - accuracy: 0.9368 - val_loss: 0.3326 - val_accuracy: 0.8612\n",
      "Epoch 41/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1854 - accuracy: 0.9375 - val_loss: 0.3309 - val_accuracy: 0.8626\n",
      "Epoch 42/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1838 - accuracy: 0.9370 - val_loss: 0.3293 - val_accuracy: 0.8626\n",
      "Epoch 43/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1822 - accuracy: 0.9382 - val_loss: 0.3276 - val_accuracy: 0.8626\n",
      "Epoch 44/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1808 - accuracy: 0.9389 - val_loss: 0.3260 - val_accuracy: 0.8626\n",
      "Epoch 45/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1795 - accuracy: 0.9384 - val_loss: 0.3245 - val_accuracy: 0.8626\n",
      "Epoch 46/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1783 - accuracy: 0.9389 - val_loss: 0.3232 - val_accuracy: 0.8640\n",
      "Epoch 47/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1771 - accuracy: 0.9377 - val_loss: 0.3222 - val_accuracy: 0.8626\n",
      "Epoch 48/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1760 - accuracy: 0.9399 - val_loss: 0.3209 - val_accuracy: 0.8626\n",
      "Epoch 49/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1748 - accuracy: 0.9401 - val_loss: 0.3195 - val_accuracy: 0.8654\n",
      "Epoch 50/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1739 - accuracy: 0.9399 - val_loss: 0.3185 - val_accuracy: 0.8669\n",
      "Epoch 51/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1730 - accuracy: 0.9401 - val_loss: 0.3175 - val_accuracy: 0.8654\n",
      "Epoch 52/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1721 - accuracy: 0.9403 - val_loss: 0.3162 - val_accuracy: 0.8683\n",
      "Epoch 53/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1710 - accuracy: 0.9403 - val_loss: 0.3156 - val_accuracy: 0.8669\n",
      "Epoch 54/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1702 - accuracy: 0.9408 - val_loss: 0.3143 - val_accuracy: 0.8669\n",
      "Epoch 55/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1693 - accuracy: 0.9408 - val_loss: 0.3134 - val_accuracy: 0.8669\n",
      "Epoch 56/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1685 - accuracy: 0.9410 - val_loss: 0.3123 - val_accuracy: 0.8669\n",
      "Epoch 57/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1677 - accuracy: 0.9403 - val_loss: 0.3114 - val_accuracy: 0.8697\n",
      "Epoch 58/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1671 - accuracy: 0.9406 - val_loss: 0.3108 - val_accuracy: 0.8711\n",
      "Epoch 59/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1663 - accuracy: 0.9415 - val_loss: 0.3101 - val_accuracy: 0.8711\n",
      "Epoch 60/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1656 - accuracy: 0.9415 - val_loss: 0.3095 - val_accuracy: 0.8711\n",
      "Epoch 61/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1649 - accuracy: 0.9406 - val_loss: 0.3088 - val_accuracy: 0.8711\n",
      "Epoch 62/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1643 - accuracy: 0.9413 - val_loss: 0.3081 - val_accuracy: 0.8711\n",
      "Epoch 63/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1638 - accuracy: 0.9417 - val_loss: 0.3073 - val_accuracy: 0.8711\n",
      "Epoch 64/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1631 - accuracy: 0.9425 - val_loss: 0.3067 - val_accuracy: 0.8711\n",
      "Epoch 65/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1625 - accuracy: 0.9434 - val_loss: 0.3060 - val_accuracy: 0.8711\n",
      "Epoch 66/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1620 - accuracy: 0.9429 - val_loss: 0.3054 - val_accuracy: 0.8711\n",
      "Epoch 67/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1613 - accuracy: 0.9432 - val_loss: 0.3046 - val_accuracy: 0.8711\n",
      "Epoch 68/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1611 - accuracy: 0.9434 - val_loss: 0.3040 - val_accuracy: 0.8711\n",
      "Epoch 69/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1603 - accuracy: 0.9427 - val_loss: 0.3034 - val_accuracy: 0.8711\n",
      "Epoch 70/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1599 - accuracy: 0.9439 - val_loss: 0.3029 - val_accuracy: 0.8711\n",
      "Epoch 71/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1594 - accuracy: 0.9443 - val_loss: 0.3025 - val_accuracy: 0.8711\n",
      "Epoch 72/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1589 - accuracy: 0.9439 - val_loss: 0.3021 - val_accuracy: 0.8725\n",
      "Epoch 73/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1585 - accuracy: 0.9439 - val_loss: 0.3015 - val_accuracy: 0.8739\n",
      "Epoch 74/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1581 - accuracy: 0.9441 - val_loss: 0.3010 - val_accuracy: 0.8739\n",
      "Epoch 75/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1577 - accuracy: 0.9441 - val_loss: 0.3005 - val_accuracy: 0.8739\n",
      "Epoch 76/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1572 - accuracy: 0.9436 - val_loss: 0.2997 - val_accuracy: 0.8725\n",
      "Epoch 77/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1567 - accuracy: 0.9443 - val_loss: 0.2995 - val_accuracy: 0.8725\n",
      "Epoch 78/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1564 - accuracy: 0.9448 - val_loss: 0.2989 - val_accuracy: 0.8725\n",
      "Epoch 79/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1559 - accuracy: 0.9446 - val_loss: 0.2984 - val_accuracy: 0.8725\n",
      "Epoch 80/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1556 - accuracy: 0.9448 - val_loss: 0.2980 - val_accuracy: 0.8725\n",
      "Epoch 81/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1552 - accuracy: 0.9448 - val_loss: 0.2978 - val_accuracy: 0.8725\n",
      "Epoch 82/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1549 - accuracy: 0.9448 - val_loss: 0.2975 - val_accuracy: 0.8739\n",
      "Epoch 83/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1545 - accuracy: 0.9446 - val_loss: 0.2968 - val_accuracy: 0.8725\n",
      "Epoch 84/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1540 - accuracy: 0.9448 - val_loss: 0.2964 - val_accuracy: 0.8739\n",
      "Epoch 85/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1538 - accuracy: 0.9443 - val_loss: 0.2959 - val_accuracy: 0.8725\n",
      "Epoch 86/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1534 - accuracy: 0.9446 - val_loss: 0.2954 - val_accuracy: 0.8711\n",
      "Epoch 87/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1530 - accuracy: 0.9446 - val_loss: 0.2951 - val_accuracy: 0.8725\n",
      "Epoch 88/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1528 - accuracy: 0.9448 - val_loss: 0.2948 - val_accuracy: 0.8725\n",
      "Epoch 89/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1523 - accuracy: 0.9450 - val_loss: 0.2943 - val_accuracy: 0.8739\n",
      "Epoch 90/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1521 - accuracy: 0.9448 - val_loss: 0.2938 - val_accuracy: 0.8739\n",
      "Epoch 91/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1519 - accuracy: 0.9450 - val_loss: 0.2936 - val_accuracy: 0.8739\n",
      "Epoch 92/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1515 - accuracy: 0.9455 - val_loss: 0.2934 - val_accuracy: 0.8739\n",
      "Epoch 93/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1513 - accuracy: 0.9455 - val_loss: 0.2929 - val_accuracy: 0.8754\n",
      "Epoch 94/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1510 - accuracy: 0.9448 - val_loss: 0.2927 - val_accuracy: 0.8754\n",
      "Epoch 95/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1507 - accuracy: 0.9450 - val_loss: 0.2923 - val_accuracy: 0.8768\n",
      "Epoch 96/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1504 - accuracy: 0.9450 - val_loss: 0.2921 - val_accuracy: 0.8782\n",
      "Epoch 97/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1501 - accuracy: 0.9453 - val_loss: 0.2919 - val_accuracy: 0.8782\n",
      "Epoch 98/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1498 - accuracy: 0.9458 - val_loss: 0.2915 - val_accuracy: 0.8782\n",
      "Epoch 99/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1497 - accuracy: 0.9453 - val_loss: 0.2913 - val_accuracy: 0.8782\n",
      "Epoch 100/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1493 - accuracy: 0.9455 - val_loss: 0.2911 - val_accuracy: 0.8782\n",
      "Epoch 101/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1490 - accuracy: 0.9453 - val_loss: 0.2907 - val_accuracy: 0.8782\n",
      "Epoch 102/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1487 - accuracy: 0.9453 - val_loss: 0.2904 - val_accuracy: 0.8782\n",
      "Epoch 103/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1485 - accuracy: 0.9453 - val_loss: 0.2901 - val_accuracy: 0.8796\n",
      "Epoch 104/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1483 - accuracy: 0.9455 - val_loss: 0.2898 - val_accuracy: 0.8810\n",
      "Epoch 105/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1480 - accuracy: 0.9458 - val_loss: 0.2897 - val_accuracy: 0.8796\n",
      "Epoch 106/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1479 - accuracy: 0.9455 - val_loss: 0.2894 - val_accuracy: 0.8796\n",
      "Epoch 107/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1476 - accuracy: 0.9458 - val_loss: 0.2891 - val_accuracy: 0.8810\n",
      "Epoch 108/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1474 - accuracy: 0.9455 - val_loss: 0.2888 - val_accuracy: 0.8810\n",
      "Epoch 109/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1473 - accuracy: 0.9458 - val_loss: 0.2887 - val_accuracy: 0.8810\n",
      "Epoch 110/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1469 - accuracy: 0.9458 - val_loss: 0.2884 - val_accuracy: 0.8810\n",
      "Epoch 111/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1467 - accuracy: 0.9458 - val_loss: 0.2882 - val_accuracy: 0.8810\n",
      "Epoch 112/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1465 - accuracy: 0.9465 - val_loss: 0.2880 - val_accuracy: 0.8810\n",
      "Epoch 113/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1463 - accuracy: 0.9460 - val_loss: 0.2876 - val_accuracy: 0.8810\n",
      "Epoch 114/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1460 - accuracy: 0.9465 - val_loss: 0.2873 - val_accuracy: 0.8796\n",
      "Epoch 115/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1459 - accuracy: 0.9458 - val_loss: 0.2871 - val_accuracy: 0.8796\n",
      "Epoch 116/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1456 - accuracy: 0.9462 - val_loss: 0.2869 - val_accuracy: 0.8796\n",
      "Epoch 117/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1455 - accuracy: 0.9460 - val_loss: 0.2868 - val_accuracy: 0.8796\n",
      "Epoch 118/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1453 - accuracy: 0.9467 - val_loss: 0.2866 - val_accuracy: 0.8796\n",
      "Epoch 119/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1451 - accuracy: 0.9467 - val_loss: 0.2862 - val_accuracy: 0.8796\n",
      "Epoch 120/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1448 - accuracy: 0.9465 - val_loss: 0.2861 - val_accuracy: 0.8782\n",
      "Epoch 121/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1447 - accuracy: 0.9462 - val_loss: 0.2860 - val_accuracy: 0.8782\n",
      "Epoch 122/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1444 - accuracy: 0.9460 - val_loss: 0.2857 - val_accuracy: 0.8782\n",
      "Epoch 123/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1443 - accuracy: 0.9462 - val_loss: 0.2854 - val_accuracy: 0.8782\n",
      "Epoch 124/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1441 - accuracy: 0.9465 - val_loss: 0.2853 - val_accuracy: 0.8782\n",
      "Epoch 125/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1440 - accuracy: 0.9467 - val_loss: 0.2850 - val_accuracy: 0.8810\n",
      "Epoch 126/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1439 - accuracy: 0.9467 - val_loss: 0.2849 - val_accuracy: 0.8796\n",
      "Epoch 127/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1435 - accuracy: 0.9469 - val_loss: 0.2846 - val_accuracy: 0.8810\n",
      "Epoch 128/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1434 - accuracy: 0.9467 - val_loss: 0.2845 - val_accuracy: 0.8810\n",
      "Epoch 129/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1432 - accuracy: 0.9465 - val_loss: 0.2842 - val_accuracy: 0.8810\n",
      "Epoch 130/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1431 - accuracy: 0.9467 - val_loss: 0.2841 - val_accuracy: 0.8810\n",
      "Epoch 131/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1429 - accuracy: 0.9472 - val_loss: 0.2840 - val_accuracy: 0.8810\n",
      "Epoch 132/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1428 - accuracy: 0.9476 - val_loss: 0.2840 - val_accuracy: 0.8824\n",
      "Epoch 133/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1426 - accuracy: 0.9474 - val_loss: 0.2837 - val_accuracy: 0.8810\n",
      "Epoch 134/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1424 - accuracy: 0.9474 - val_loss: 0.2835 - val_accuracy: 0.8796\n",
      "Epoch 135/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1423 - accuracy: 0.9472 - val_loss: 0.2835 - val_accuracy: 0.8824\n",
      "Epoch 136/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1421 - accuracy: 0.9479 - val_loss: 0.2833 - val_accuracy: 0.8824\n",
      "Epoch 137/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1419 - accuracy: 0.9472 - val_loss: 0.2832 - val_accuracy: 0.8824\n",
      "Epoch 138/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1417 - accuracy: 0.9476 - val_loss: 0.2829 - val_accuracy: 0.8810\n",
      "Epoch 139/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1415 - accuracy: 0.9474 - val_loss: 0.2826 - val_accuracy: 0.8810\n",
      "Epoch 140/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1414 - accuracy: 0.9474 - val_loss: 0.2825 - val_accuracy: 0.8810\n",
      "Epoch 141/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1414 - accuracy: 0.9476 - val_loss: 0.2824 - val_accuracy: 0.8824\n",
      "Epoch 142/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1411 - accuracy: 0.9472 - val_loss: 0.2823 - val_accuracy: 0.8824\n",
      "Epoch 143/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1410 - accuracy: 0.9472 - val_loss: 0.2820 - val_accuracy: 0.8810\n",
      "Epoch 144/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1408 - accuracy: 0.9474 - val_loss: 0.2820 - val_accuracy: 0.8824\n",
      "Epoch 145/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1407 - accuracy: 0.9474 - val_loss: 0.2818 - val_accuracy: 0.8824\n",
      "Epoch 146/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1405 - accuracy: 0.9472 - val_loss: 0.2815 - val_accuracy: 0.8810\n",
      "Epoch 147/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1404 - accuracy: 0.9474 - val_loss: 0.2814 - val_accuracy: 0.8796\n",
      "Epoch 148/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1402 - accuracy: 0.9474 - val_loss: 0.2813 - val_accuracy: 0.8810\n",
      "Epoch 149/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1401 - accuracy: 0.9476 - val_loss: 0.2811 - val_accuracy: 0.8810\n",
      "Epoch 150/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1399 - accuracy: 0.9476 - val_loss: 0.2810 - val_accuracy: 0.8810\n",
      "Epoch 151/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1397 - accuracy: 0.9474 - val_loss: 0.2808 - val_accuracy: 0.8810\n",
      "Epoch 152/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1398 - accuracy: 0.9474 - val_loss: 0.2806 - val_accuracy: 0.8796\n",
      "Epoch 153/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1396 - accuracy: 0.9472 - val_loss: 0.2806 - val_accuracy: 0.8810\n",
      "Epoch 154/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1395 - accuracy: 0.9481 - val_loss: 0.2806 - val_accuracy: 0.8810\n",
      "Epoch 155/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1393 - accuracy: 0.9474 - val_loss: 0.2804 - val_accuracy: 0.8810\n",
      "Epoch 156/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1391 - accuracy: 0.9479 - val_loss: 0.2802 - val_accuracy: 0.8810\n",
      "Epoch 157/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1389 - accuracy: 0.9486 - val_loss: 0.2800 - val_accuracy: 0.8824\n",
      "Epoch 158/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1389 - accuracy: 0.9476 - val_loss: 0.2799 - val_accuracy: 0.8824\n",
      "Epoch 159/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1388 - accuracy: 0.9481 - val_loss: 0.2797 - val_accuracy: 0.8824\n",
      "Epoch 160/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1386 - accuracy: 0.9479 - val_loss: 0.2796 - val_accuracy: 0.8824\n",
      "Epoch 161/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1385 - accuracy: 0.9481 - val_loss: 0.2795 - val_accuracy: 0.8824\n",
      "Epoch 162/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1384 - accuracy: 0.9483 - val_loss: 0.2795 - val_accuracy: 0.8824\n",
      "Epoch 163/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1384 - accuracy: 0.9481 - val_loss: 0.2793 - val_accuracy: 0.8824\n",
      "Epoch 164/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1382 - accuracy: 0.9479 - val_loss: 0.2792 - val_accuracy: 0.8824\n",
      "Epoch 165/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1380 - accuracy: 0.9481 - val_loss: 0.2790 - val_accuracy: 0.8824\n",
      "Epoch 166/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1378 - accuracy: 0.9488 - val_loss: 0.2789 - val_accuracy: 0.8824\n",
      "Epoch 167/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1378 - accuracy: 0.9483 - val_loss: 0.2788 - val_accuracy: 0.8824\n",
      "Epoch 168/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1377 - accuracy: 0.9481 - val_loss: 0.2787 - val_accuracy: 0.8824\n",
      "Epoch 169/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1376 - accuracy: 0.9491 - val_loss: 0.2787 - val_accuracy: 0.8824\n",
      "Epoch 170/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1374 - accuracy: 0.9483 - val_loss: 0.2786 - val_accuracy: 0.8824\n",
      "Epoch 171/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1373 - accuracy: 0.9486 - val_loss: 0.2785 - val_accuracy: 0.8824\n",
      "Epoch 172/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1372 - accuracy: 0.9488 - val_loss: 0.2783 - val_accuracy: 0.8824\n",
      "Epoch 173/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1371 - accuracy: 0.9481 - val_loss: 0.2783 - val_accuracy: 0.8839\n",
      "Epoch 174/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1370 - accuracy: 0.9483 - val_loss: 0.2781 - val_accuracy: 0.8839\n",
      "Epoch 175/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1368 - accuracy: 0.9486 - val_loss: 0.2780 - val_accuracy: 0.8839\n",
      "Epoch 176/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1366 - accuracy: 0.9488 - val_loss: 0.2778 - val_accuracy: 0.8839\n",
      "Epoch 177/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1366 - accuracy: 0.9488 - val_loss: 0.2777 - val_accuracy: 0.8824\n",
      "Epoch 178/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1364 - accuracy: 0.9486 - val_loss: 0.2776 - val_accuracy: 0.8839\n",
      "Epoch 179/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1364 - accuracy: 0.9481 - val_loss: 0.2776 - val_accuracy: 0.8839\n",
      "Epoch 180/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1363 - accuracy: 0.9488 - val_loss: 0.2776 - val_accuracy: 0.8839\n",
      "Epoch 181/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1361 - accuracy: 0.9486 - val_loss: 0.2774 - val_accuracy: 0.8839\n",
      "Epoch 182/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1360 - accuracy: 0.9491 - val_loss: 0.2775 - val_accuracy: 0.8839\n",
      "Epoch 183/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1359 - accuracy: 0.9486 - val_loss: 0.2773 - val_accuracy: 0.8839\n",
      "Epoch 184/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1358 - accuracy: 0.9488 - val_loss: 0.2772 - val_accuracy: 0.8839\n",
      "Epoch 185/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1357 - accuracy: 0.9483 - val_loss: 0.2770 - val_accuracy: 0.8824\n",
      "Epoch 186/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1355 - accuracy: 0.9486 - val_loss: 0.2770 - val_accuracy: 0.8824\n",
      "Epoch 187/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1355 - accuracy: 0.9483 - val_loss: 0.2770 - val_accuracy: 0.8839\n",
      "Epoch 188/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1354 - accuracy: 0.9481 - val_loss: 0.2769 - val_accuracy: 0.8839\n",
      "Epoch 189/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1353 - accuracy: 0.9486 - val_loss: 0.2769 - val_accuracy: 0.8839\n",
      "Epoch 190/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1352 - accuracy: 0.9491 - val_loss: 0.2767 - val_accuracy: 0.8824\n",
      "Epoch 191/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1350 - accuracy: 0.9486 - val_loss: 0.2765 - val_accuracy: 0.8839\n",
      "Epoch 192/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1350 - accuracy: 0.9488 - val_loss: 0.2765 - val_accuracy: 0.8824\n",
      "Epoch 193/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1348 - accuracy: 0.9483 - val_loss: 0.2764 - val_accuracy: 0.8839\n",
      "Epoch 194/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1348 - accuracy: 0.9483 - val_loss: 0.2764 - val_accuracy: 0.8853\n",
      "Epoch 195/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1347 - accuracy: 0.9488 - val_loss: 0.2762 - val_accuracy: 0.8839\n",
      "Epoch 196/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1345 - accuracy: 0.9486 - val_loss: 0.2762 - val_accuracy: 0.8839\n",
      "Epoch 197/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1344 - accuracy: 0.9491 - val_loss: 0.2760 - val_accuracy: 0.8839\n",
      "Epoch 198/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1344 - accuracy: 0.9486 - val_loss: 0.2761 - val_accuracy: 0.8867\n",
      "Epoch 199/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1342 - accuracy: 0.9491 - val_loss: 0.2760 - val_accuracy: 0.8853\n",
      "Epoch 200/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1341 - accuracy: 0.9486 - val_loss: 0.2759 - val_accuracy: 0.8839\n",
      "Epoch 201/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1340 - accuracy: 0.9486 - val_loss: 0.2758 - val_accuracy: 0.8839\n",
      "Epoch 202/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1340 - accuracy: 0.9491 - val_loss: 0.2756 - val_accuracy: 0.8839\n",
      "Epoch 203/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1339 - accuracy: 0.9491 - val_loss: 0.2757 - val_accuracy: 0.8839\n",
      "Epoch 204/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1338 - accuracy: 0.9488 - val_loss: 0.2757 - val_accuracy: 0.8853\n",
      "Epoch 205/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1336 - accuracy: 0.9483 - val_loss: 0.2756 - val_accuracy: 0.8839\n",
      "Epoch 206/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1336 - accuracy: 0.9493 - val_loss: 0.2755 - val_accuracy: 0.8853\n",
      "Epoch 207/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1335 - accuracy: 0.9486 - val_loss: 0.2753 - val_accuracy: 0.8839\n",
      "Epoch 208/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1333 - accuracy: 0.9486 - val_loss: 0.2755 - val_accuracy: 0.8853\n",
      "Epoch 209/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1332 - accuracy: 0.9488 - val_loss: 0.2753 - val_accuracy: 0.8853\n",
      "Epoch 210/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1332 - accuracy: 0.9488 - val_loss: 0.2751 - val_accuracy: 0.8824\n",
      "Epoch 211/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1331 - accuracy: 0.9495 - val_loss: 0.2751 - val_accuracy: 0.8839\n",
      "Epoch 212/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1330 - accuracy: 0.9488 - val_loss: 0.2751 - val_accuracy: 0.8839\n",
      "Epoch 213/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1328 - accuracy: 0.9486 - val_loss: 0.2749 - val_accuracy: 0.8824\n",
      "Epoch 214/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1328 - accuracy: 0.9495 - val_loss: 0.2749 - val_accuracy: 0.8824\n",
      "Epoch 215/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1326 - accuracy: 0.9498 - val_loss: 0.2747 - val_accuracy: 0.8839\n",
      "Epoch 216/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1326 - accuracy: 0.9486 - val_loss: 0.2747 - val_accuracy: 0.8839\n",
      "Epoch 217/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1325 - accuracy: 0.9493 - val_loss: 0.2745 - val_accuracy: 0.8839\n",
      "Epoch 218/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1324 - accuracy: 0.9488 - val_loss: 0.2747 - val_accuracy: 0.8839\n",
      "Epoch 219/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1324 - accuracy: 0.9495 - val_loss: 0.2746 - val_accuracy: 0.8839\n",
      "Epoch 220/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1322 - accuracy: 0.9491 - val_loss: 0.2747 - val_accuracy: 0.8853\n",
      "Epoch 221/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1322 - accuracy: 0.9486 - val_loss: 0.2745 - val_accuracy: 0.8839\n",
      "Epoch 222/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1320 - accuracy: 0.9491 - val_loss: 0.2745 - val_accuracy: 0.8853\n",
      "Epoch 223/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1320 - accuracy: 0.9495 - val_loss: 0.2744 - val_accuracy: 0.8839\n",
      "Epoch 224/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1319 - accuracy: 0.9495 - val_loss: 0.2744 - val_accuracy: 0.8853\n",
      "Epoch 225/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1318 - accuracy: 0.9491 - val_loss: 0.2742 - val_accuracy: 0.8853\n",
      "Epoch 226/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1317 - accuracy: 0.9488 - val_loss: 0.2742 - val_accuracy: 0.8867\n",
      "Epoch 227/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1316 - accuracy: 0.9498 - val_loss: 0.2740 - val_accuracy: 0.8853\n",
      "Epoch 228/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1315 - accuracy: 0.9502 - val_loss: 0.2740 - val_accuracy: 0.8853\n",
      "Epoch 229/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1314 - accuracy: 0.9505 - val_loss: 0.2741 - val_accuracy: 0.8853\n",
      "Epoch 230/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1313 - accuracy: 0.9495 - val_loss: 0.2739 - val_accuracy: 0.8839\n",
      "Epoch 231/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1312 - accuracy: 0.9500 - val_loss: 0.2740 - val_accuracy: 0.8853\n",
      "Epoch 232/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1311 - accuracy: 0.9493 - val_loss: 0.2739 - val_accuracy: 0.8839\n",
      "Epoch 233/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1310 - accuracy: 0.9498 - val_loss: 0.2739 - val_accuracy: 0.8839\n",
      "Epoch 234/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1310 - accuracy: 0.9502 - val_loss: 0.2737 - val_accuracy: 0.8839\n",
      "Epoch 235/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1309 - accuracy: 0.9495 - val_loss: 0.2738 - val_accuracy: 0.8824\n",
      "Epoch 236/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1308 - accuracy: 0.9502 - val_loss: 0.2736 - val_accuracy: 0.8824\n",
      "Epoch 237/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1308 - accuracy: 0.9491 - val_loss: 0.2736 - val_accuracy: 0.8824\n",
      "Epoch 238/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1306 - accuracy: 0.9493 - val_loss: 0.2737 - val_accuracy: 0.8839\n",
      "Epoch 239/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1305 - accuracy: 0.9505 - val_loss: 0.2734 - val_accuracy: 0.8824\n",
      "Epoch 240/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1305 - accuracy: 0.9498 - val_loss: 0.2734 - val_accuracy: 0.8824\n",
      "Epoch 241/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1303 - accuracy: 0.9498 - val_loss: 0.2733 - val_accuracy: 0.8824\n",
      "Epoch 242/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1303 - accuracy: 0.9502 - val_loss: 0.2733 - val_accuracy: 0.8824\n",
      "Epoch 243/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1301 - accuracy: 0.9505 - val_loss: 0.2733 - val_accuracy: 0.8824\n",
      "Epoch 244/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1301 - accuracy: 0.9502 - val_loss: 0.2732 - val_accuracy: 0.8824\n",
      "Epoch 245/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1300 - accuracy: 0.9498 - val_loss: 0.2732 - val_accuracy: 0.8824\n",
      "Epoch 246/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1300 - accuracy: 0.9498 - val_loss: 0.2731 - val_accuracy: 0.8824\n",
      "Epoch 247/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1298 - accuracy: 0.9500 - val_loss: 0.2731 - val_accuracy: 0.8824\n",
      "Epoch 248/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1298 - accuracy: 0.9509 - val_loss: 0.2731 - val_accuracy: 0.8824\n",
      "Epoch 249/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1297 - accuracy: 0.9502 - val_loss: 0.2730 - val_accuracy: 0.8824\n",
      "Epoch 250/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1297 - accuracy: 0.9507 - val_loss: 0.2731 - val_accuracy: 0.8839\n",
      "Epoch 251/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1296 - accuracy: 0.9507 - val_loss: 0.2730 - val_accuracy: 0.8839\n",
      "Epoch 252/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1295 - accuracy: 0.9507 - val_loss: 0.2731 - val_accuracy: 0.8839\n",
      "Epoch 253/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1294 - accuracy: 0.9509 - val_loss: 0.2728 - val_accuracy: 0.8824\n",
      "Epoch 254/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1295 - accuracy: 0.9498 - val_loss: 0.2727 - val_accuracy: 0.8824\n",
      "Epoch 255/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1292 - accuracy: 0.9505 - val_loss: 0.2727 - val_accuracy: 0.8824\n",
      "Epoch 256/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1291 - accuracy: 0.9505 - val_loss: 0.2727 - val_accuracy: 0.8839\n",
      "Epoch 257/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1292 - accuracy: 0.9500 - val_loss: 0.2726 - val_accuracy: 0.8839\n",
      "Epoch 258/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1290 - accuracy: 0.9507 - val_loss: 0.2725 - val_accuracy: 0.8839\n",
      "Epoch 259/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1290 - accuracy: 0.9514 - val_loss: 0.2725 - val_accuracy: 0.8839\n",
      "Epoch 260/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1289 - accuracy: 0.9512 - val_loss: 0.2726 - val_accuracy: 0.8839\n",
      "Epoch 261/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1288 - accuracy: 0.9509 - val_loss: 0.2724 - val_accuracy: 0.8839\n",
      "Epoch 262/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1288 - accuracy: 0.9514 - val_loss: 0.2724 - val_accuracy: 0.8839\n",
      "Epoch 263/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1286 - accuracy: 0.9512 - val_loss: 0.2723 - val_accuracy: 0.8839\n",
      "Epoch 264/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1285 - accuracy: 0.9512 - val_loss: 0.2723 - val_accuracy: 0.8839\n",
      "Epoch 265/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1285 - accuracy: 0.9512 - val_loss: 0.2721 - val_accuracy: 0.8839\n",
      "Epoch 266/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1285 - accuracy: 0.9514 - val_loss: 0.2722 - val_accuracy: 0.8839\n",
      "Epoch 267/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1284 - accuracy: 0.9519 - val_loss: 0.2722 - val_accuracy: 0.8839\n",
      "Epoch 268/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1283 - accuracy: 0.9514 - val_loss: 0.2722 - val_accuracy: 0.8839\n",
      "Epoch 269/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1282 - accuracy: 0.9519 - val_loss: 0.2721 - val_accuracy: 0.8839\n",
      "Epoch 270/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1282 - accuracy: 0.9509 - val_loss: 0.2720 - val_accuracy: 0.8839\n",
      "Epoch 271/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1281 - accuracy: 0.9512 - val_loss: 0.2720 - val_accuracy: 0.8839\n",
      "Epoch 272/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1279 - accuracy: 0.9524 - val_loss: 0.2720 - val_accuracy: 0.8839\n",
      "Epoch 273/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1281 - accuracy: 0.9517 - val_loss: 0.2720 - val_accuracy: 0.8839\n",
      "Epoch 274/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1279 - accuracy: 0.9519 - val_loss: 0.2720 - val_accuracy: 0.8839\n",
      "Epoch 275/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1278 - accuracy: 0.9517 - val_loss: 0.2718 - val_accuracy: 0.8839\n",
      "Epoch 276/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1277 - accuracy: 0.9514 - val_loss: 0.2719 - val_accuracy: 0.8839\n",
      "Epoch 277/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1276 - accuracy: 0.9519 - val_loss: 0.2718 - val_accuracy: 0.8824\n",
      "Epoch 278/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1275 - accuracy: 0.9517 - val_loss: 0.2717 - val_accuracy: 0.8810\n",
      "Epoch 279/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1275 - accuracy: 0.9514 - val_loss: 0.2717 - val_accuracy: 0.8810\n",
      "Epoch 280/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1274 - accuracy: 0.9517 - val_loss: 0.2716 - val_accuracy: 0.8810\n",
      "Epoch 281/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1274 - accuracy: 0.9517 - val_loss: 0.2717 - val_accuracy: 0.8810\n",
      "Epoch 282/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1273 - accuracy: 0.9519 - val_loss: 0.2715 - val_accuracy: 0.8810\n",
      "Epoch 283/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1272 - accuracy: 0.9517 - val_loss: 0.2716 - val_accuracy: 0.8810\n",
      "Epoch 284/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1271 - accuracy: 0.9519 - val_loss: 0.2714 - val_accuracy: 0.8810\n",
      "Epoch 285/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1271 - accuracy: 0.9519 - val_loss: 0.2715 - val_accuracy: 0.8810\n",
      "Epoch 286/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1270 - accuracy: 0.9514 - val_loss: 0.2713 - val_accuracy: 0.8810\n",
      "Epoch 287/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1269 - accuracy: 0.9521 - val_loss: 0.2714 - val_accuracy: 0.8810\n",
      "Epoch 288/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1270 - accuracy: 0.9517 - val_loss: 0.2715 - val_accuracy: 0.8810\n",
      "Epoch 289/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1268 - accuracy: 0.9519 - val_loss: 0.2713 - val_accuracy: 0.8810\n",
      "Epoch 290/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1268 - accuracy: 0.9519 - val_loss: 0.2715 - val_accuracy: 0.8810\n",
      "Epoch 291/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1266 - accuracy: 0.9517 - val_loss: 0.2714 - val_accuracy: 0.8810\n",
      "Epoch 292/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1266 - accuracy: 0.9517 - val_loss: 0.2713 - val_accuracy: 0.8810\n",
      "Epoch 293/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1266 - accuracy: 0.9519 - val_loss: 0.2714 - val_accuracy: 0.8796\n",
      "Epoch 294/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1265 - accuracy: 0.9519 - val_loss: 0.2713 - val_accuracy: 0.8796\n",
      "Epoch 295/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1265 - accuracy: 0.9517 - val_loss: 0.2713 - val_accuracy: 0.8810\n",
      "Epoch 296/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1264 - accuracy: 0.9514 - val_loss: 0.2712 - val_accuracy: 0.8810\n",
      "Epoch 297/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1263 - accuracy: 0.9519 - val_loss: 0.2712 - val_accuracy: 0.8810\n",
      "Epoch 298/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1262 - accuracy: 0.9519 - val_loss: 0.2713 - val_accuracy: 0.8796\n",
      "Epoch 299/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1261 - accuracy: 0.9519 - val_loss: 0.2712 - val_accuracy: 0.8796\n",
      "Epoch 300/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1261 - accuracy: 0.9517 - val_loss: 0.2710 - val_accuracy: 0.8796\n",
      "Epoch 301/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1259 - accuracy: 0.9521 - val_loss: 0.2710 - val_accuracy: 0.8796\n",
      "Epoch 302/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1258 - accuracy: 0.9519 - val_loss: 0.2710 - val_accuracy: 0.8810\n",
      "Epoch 303/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1258 - accuracy: 0.9519 - val_loss: 0.2709 - val_accuracy: 0.8796\n",
      "Epoch 304/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1258 - accuracy: 0.9521 - val_loss: 0.2709 - val_accuracy: 0.8796\n",
      "Epoch 305/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1256 - accuracy: 0.9517 - val_loss: 0.2710 - val_accuracy: 0.8810\n",
      "Epoch 306/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1257 - accuracy: 0.9521 - val_loss: 0.2709 - val_accuracy: 0.8810\n",
      "Epoch 307/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1257 - accuracy: 0.9517 - val_loss: 0.2709 - val_accuracy: 0.8810\n",
      "Epoch 308/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1255 - accuracy: 0.9517 - val_loss: 0.2709 - val_accuracy: 0.8810\n",
      "Epoch 309/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1254 - accuracy: 0.9519 - val_loss: 0.2708 - val_accuracy: 0.8810\n",
      "Epoch 310/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1254 - accuracy: 0.9521 - val_loss: 0.2708 - val_accuracy: 0.8810\n",
      "Epoch 311/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1254 - accuracy: 0.9519 - val_loss: 0.2708 - val_accuracy: 0.8810\n",
      "Epoch 312/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1252 - accuracy: 0.9519 - val_loss: 0.2707 - val_accuracy: 0.8810\n",
      "Epoch 313/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1251 - accuracy: 0.9519 - val_loss: 0.2706 - val_accuracy: 0.8810\n",
      "Epoch 314/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1251 - accuracy: 0.9521 - val_loss: 0.2707 - val_accuracy: 0.8810\n",
      "Epoch 315/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1251 - accuracy: 0.9519 - val_loss: 0.2707 - val_accuracy: 0.8810\n",
      "Epoch 316/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1250 - accuracy: 0.9519 - val_loss: 0.2707 - val_accuracy: 0.8810\n",
      "Epoch 317/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1249 - accuracy: 0.9519 - val_loss: 0.2705 - val_accuracy: 0.8810\n",
      "Epoch 318/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1249 - accuracy: 0.9517 - val_loss: 0.2705 - val_accuracy: 0.8824\n",
      "Epoch 319/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1248 - accuracy: 0.9521 - val_loss: 0.2704 - val_accuracy: 0.8824\n",
      "Epoch 320/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1248 - accuracy: 0.9521 - val_loss: 0.2705 - val_accuracy: 0.8810\n",
      "Epoch 321/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1248 - accuracy: 0.9519 - val_loss: 0.2704 - val_accuracy: 0.8824\n",
      "Epoch 322/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1246 - accuracy: 0.9526 - val_loss: 0.2705 - val_accuracy: 0.8824\n",
      "Epoch 323/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1245 - accuracy: 0.9521 - val_loss: 0.2703 - val_accuracy: 0.8824\n",
      "Epoch 324/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1245 - accuracy: 0.9524 - val_loss: 0.2704 - val_accuracy: 0.8824\n",
      "Epoch 325/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1245 - accuracy: 0.9524 - val_loss: 0.2704 - val_accuracy: 0.8824\n",
      "Epoch 326/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1244 - accuracy: 0.9528 - val_loss: 0.2703 - val_accuracy: 0.8824\n",
      "Epoch 327/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1243 - accuracy: 0.9524 - val_loss: 0.2703 - val_accuracy: 0.8824\n",
      "Epoch 328/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1242 - accuracy: 0.9524 - val_loss: 0.2702 - val_accuracy: 0.8824\n",
      "Epoch 329/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1242 - accuracy: 0.9524 - val_loss: 0.2703 - val_accuracy: 0.8824\n",
      "Epoch 330/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1241 - accuracy: 0.9521 - val_loss: 0.2702 - val_accuracy: 0.8824\n",
      "Epoch 331/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1241 - accuracy: 0.9519 - val_loss: 0.2702 - val_accuracy: 0.8824\n",
      "Epoch 332/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1240 - accuracy: 0.9526 - val_loss: 0.2702 - val_accuracy: 0.8824\n",
      "Epoch 333/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1239 - accuracy: 0.9524 - val_loss: 0.2701 - val_accuracy: 0.8824\n",
      "Epoch 334/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1239 - accuracy: 0.9526 - val_loss: 0.2700 - val_accuracy: 0.8824\n",
      "Epoch 335/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1238 - accuracy: 0.9521 - val_loss: 0.2700 - val_accuracy: 0.8824\n",
      "Epoch 336/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1236 - accuracy: 0.9526 - val_loss: 0.2699 - val_accuracy: 0.8824\n",
      "Epoch 337/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1237 - accuracy: 0.9524 - val_loss: 0.2700 - val_accuracy: 0.8824\n",
      "Epoch 338/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1236 - accuracy: 0.9524 - val_loss: 0.2699 - val_accuracy: 0.8824\n",
      "Epoch 339/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1235 - accuracy: 0.9526 - val_loss: 0.2699 - val_accuracy: 0.8824\n",
      "Epoch 340/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1234 - accuracy: 0.9528 - val_loss: 0.2699 - val_accuracy: 0.8824\n",
      "Epoch 341/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1234 - accuracy: 0.9524 - val_loss: 0.2699 - val_accuracy: 0.8824\n",
      "Epoch 342/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1233 - accuracy: 0.9524 - val_loss: 0.2699 - val_accuracy: 0.8824\n",
      "Epoch 343/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1234 - accuracy: 0.9524 - val_loss: 0.2700 - val_accuracy: 0.8824\n",
      "Epoch 344/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1233 - accuracy: 0.9526 - val_loss: 0.2700 - val_accuracy: 0.8824\n",
      "Epoch 345/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1232 - accuracy: 0.9524 - val_loss: 0.2699 - val_accuracy: 0.8824\n",
      "Epoch 346/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1231 - accuracy: 0.9524 - val_loss: 0.2699 - val_accuracy: 0.8824\n",
      "Epoch 347/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1231 - accuracy: 0.9526 - val_loss: 0.2698 - val_accuracy: 0.8824\n",
      "Epoch 348/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1231 - accuracy: 0.9526 - val_loss: 0.2699 - val_accuracy: 0.8824\n",
      "Epoch 349/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1229 - accuracy: 0.9528 - val_loss: 0.2698 - val_accuracy: 0.8824\n",
      "Epoch 350/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1229 - accuracy: 0.9528 - val_loss: 0.2698 - val_accuracy: 0.8824\n",
      "Epoch 351/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1228 - accuracy: 0.9526 - val_loss: 0.2697 - val_accuracy: 0.8824\n",
      "Epoch 352/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1228 - accuracy: 0.9528 - val_loss: 0.2696 - val_accuracy: 0.8824\n",
      "Epoch 353/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1227 - accuracy: 0.9531 - val_loss: 0.2697 - val_accuracy: 0.8824\n",
      "Epoch 354/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1227 - accuracy: 0.9526 - val_loss: 0.2697 - val_accuracy: 0.8824\n",
      "Epoch 355/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1225 - accuracy: 0.9528 - val_loss: 0.2695 - val_accuracy: 0.8824\n",
      "Epoch 356/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1225 - accuracy: 0.9528 - val_loss: 0.2696 - val_accuracy: 0.8824\n",
      "Epoch 357/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1225 - accuracy: 0.9526 - val_loss: 0.2696 - val_accuracy: 0.8824\n",
      "Epoch 358/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1224 - accuracy: 0.9531 - val_loss: 0.2696 - val_accuracy: 0.8824\n",
      "Epoch 359/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1224 - accuracy: 0.9528 - val_loss: 0.2695 - val_accuracy: 0.8824\n",
      "Epoch 360/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1223 - accuracy: 0.9528 - val_loss: 0.2695 - val_accuracy: 0.8824\n",
      "Epoch 361/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1223 - accuracy: 0.9531 - val_loss: 0.2695 - val_accuracy: 0.8824\n",
      "Epoch 362/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1222 - accuracy: 0.9528 - val_loss: 0.2696 - val_accuracy: 0.8824\n",
      "Epoch 363/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1222 - accuracy: 0.9526 - val_loss: 0.2695 - val_accuracy: 0.8824\n",
      "Epoch 364/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1221 - accuracy: 0.9526 - val_loss: 0.2696 - val_accuracy: 0.8824\n",
      "Epoch 365/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1220 - accuracy: 0.9526 - val_loss: 0.2695 - val_accuracy: 0.8824\n",
      "Epoch 366/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1221 - accuracy: 0.9531 - val_loss: 0.2694 - val_accuracy: 0.8824\n",
      "Epoch 367/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1219 - accuracy: 0.9531 - val_loss: 0.2695 - val_accuracy: 0.8824\n",
      "Epoch 368/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1218 - accuracy: 0.9528 - val_loss: 0.2694 - val_accuracy: 0.8824\n",
      "Epoch 369/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1218 - accuracy: 0.9531 - val_loss: 0.2694 - val_accuracy: 0.8824\n",
      "Epoch 370/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1218 - accuracy: 0.9531 - val_loss: 0.2695 - val_accuracy: 0.8824\n",
      "Epoch 371/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1219 - accuracy: 0.9524 - val_loss: 0.2694 - val_accuracy: 0.8824\n",
      "Epoch 372/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1216 - accuracy: 0.9533 - val_loss: 0.2694 - val_accuracy: 0.8824\n",
      "Epoch 373/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1216 - accuracy: 0.9528 - val_loss: 0.2694 - val_accuracy: 0.8824\n",
      "Epoch 374/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1214 - accuracy: 0.9528 - val_loss: 0.2693 - val_accuracy: 0.8824\n",
      "Epoch 375/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1214 - accuracy: 0.9526 - val_loss: 0.2693 - val_accuracy: 0.8824\n",
      "Epoch 376/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1214 - accuracy: 0.9533 - val_loss: 0.2694 - val_accuracy: 0.8824\n",
      "Epoch 377/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1213 - accuracy: 0.9528 - val_loss: 0.2693 - val_accuracy: 0.8824\n",
      "Epoch 378/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1213 - accuracy: 0.9528 - val_loss: 0.2693 - val_accuracy: 0.8824\n",
      "Epoch 379/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1212 - accuracy: 0.9531 - val_loss: 0.2692 - val_accuracy: 0.8824\n",
      "Epoch 380/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1212 - accuracy: 0.9531 - val_loss: 0.2692 - val_accuracy: 0.8824\n",
      "Epoch 381/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1211 - accuracy: 0.9531 - val_loss: 0.2693 - val_accuracy: 0.8824\n",
      "Epoch 382/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1211 - accuracy: 0.9524 - val_loss: 0.2693 - val_accuracy: 0.8824\n",
      "Epoch 383/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1210 - accuracy: 0.9528 - val_loss: 0.2692 - val_accuracy: 0.8824\n",
      "Epoch 384/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1210 - accuracy: 0.9528 - val_loss: 0.2693 - val_accuracy: 0.8824\n",
      "Epoch 385/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1209 - accuracy: 0.9533 - val_loss: 0.2692 - val_accuracy: 0.8824\n",
      "Epoch 386/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1208 - accuracy: 0.9528 - val_loss: 0.2692 - val_accuracy: 0.8824\n",
      "Epoch 387/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1208 - accuracy: 0.9526 - val_loss: 0.2692 - val_accuracy: 0.8824\n",
      "Epoch 388/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1207 - accuracy: 0.9528 - val_loss: 0.2693 - val_accuracy: 0.8824\n",
      "Epoch 389/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1207 - accuracy: 0.9528 - val_loss: 0.2690 - val_accuracy: 0.8824\n",
      "Epoch 390/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1206 - accuracy: 0.9528 - val_loss: 0.2691 - val_accuracy: 0.8824\n",
      "Epoch 391/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1205 - accuracy: 0.9528 - val_loss: 0.2691 - val_accuracy: 0.8824\n",
      "Epoch 392/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1205 - accuracy: 0.9533 - val_loss: 0.2691 - val_accuracy: 0.8824\n",
      "Epoch 393/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1204 - accuracy: 0.9533 - val_loss: 0.2690 - val_accuracy: 0.8824\n",
      "Epoch 394/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1203 - accuracy: 0.9533 - val_loss: 0.2690 - val_accuracy: 0.8824\n",
      "Epoch 395/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1203 - accuracy: 0.9533 - val_loss: 0.2689 - val_accuracy: 0.8824\n",
      "Epoch 396/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1202 - accuracy: 0.9531 - val_loss: 0.2690 - val_accuracy: 0.8824\n",
      "Epoch 397/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1201 - accuracy: 0.9535 - val_loss: 0.2690 - val_accuracy: 0.8824\n",
      "Epoch 398/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1202 - accuracy: 0.9533 - val_loss: 0.2690 - val_accuracy: 0.8824\n",
      "Epoch 399/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1202 - accuracy: 0.9535 - val_loss: 0.2689 - val_accuracy: 0.8824\n",
      "Epoch 400/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1200 - accuracy: 0.9538 - val_loss: 0.2690 - val_accuracy: 0.8824\n",
      "Epoch 401/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1199 - accuracy: 0.9528 - val_loss: 0.2689 - val_accuracy: 0.8824\n",
      "Epoch 402/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1199 - accuracy: 0.9531 - val_loss: 0.2689 - val_accuracy: 0.8824\n",
      "Epoch 403/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1199 - accuracy: 0.9535 - val_loss: 0.2689 - val_accuracy: 0.8824\n",
      "Epoch 404/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1198 - accuracy: 0.9535 - val_loss: 0.2689 - val_accuracy: 0.8810\n",
      "Epoch 405/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1199 - accuracy: 0.9533 - val_loss: 0.2688 - val_accuracy: 0.8824\n",
      "Epoch 406/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1197 - accuracy: 0.9531 - val_loss: 0.2689 - val_accuracy: 0.8810\n",
      "Epoch 407/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1197 - accuracy: 0.9531 - val_loss: 0.2689 - val_accuracy: 0.8810\n",
      "Epoch 408/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1197 - accuracy: 0.9533 - val_loss: 0.2689 - val_accuracy: 0.8810\n",
      "Epoch 409/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1196 - accuracy: 0.9531 - val_loss: 0.2688 - val_accuracy: 0.8810\n",
      "Epoch 410/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1195 - accuracy: 0.9535 - val_loss: 0.2688 - val_accuracy: 0.8810\n",
      "Epoch 411/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1194 - accuracy: 0.9535 - val_loss: 0.2687 - val_accuracy: 0.8810\n",
      "Epoch 412/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1194 - accuracy: 0.9528 - val_loss: 0.2687 - val_accuracy: 0.8810\n",
      "Epoch 413/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1193 - accuracy: 0.9531 - val_loss: 0.2687 - val_accuracy: 0.8810\n",
      "Epoch 414/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1193 - accuracy: 0.9533 - val_loss: 0.2687 - val_accuracy: 0.8810\n",
      "Epoch 415/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1192 - accuracy: 0.9533 - val_loss: 0.2687 - val_accuracy: 0.8810\n",
      "Epoch 416/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1192 - accuracy: 0.9531 - val_loss: 0.2688 - val_accuracy: 0.8796\n",
      "Epoch 417/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1192 - accuracy: 0.9533 - val_loss: 0.2688 - val_accuracy: 0.8810\n",
      "Epoch 418/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1191 - accuracy: 0.9533 - val_loss: 0.2688 - val_accuracy: 0.8810\n",
      "Epoch 419/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1190 - accuracy: 0.9535 - val_loss: 0.2688 - val_accuracy: 0.8810\n",
      "Epoch 420/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1190 - accuracy: 0.9538 - val_loss: 0.2687 - val_accuracy: 0.8824\n",
      "Epoch 421/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1189 - accuracy: 0.9533 - val_loss: 0.2687 - val_accuracy: 0.8810\n",
      "Epoch 422/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1189 - accuracy: 0.9533 - val_loss: 0.2687 - val_accuracy: 0.8810\n",
      "Epoch 423/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1188 - accuracy: 0.9538 - val_loss: 0.2685 - val_accuracy: 0.8810\n",
      "Epoch 424/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1186 - accuracy: 0.9535 - val_loss: 0.2686 - val_accuracy: 0.8810\n",
      "Epoch 425/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1187 - accuracy: 0.9535 - val_loss: 0.2686 - val_accuracy: 0.8810\n",
      "Epoch 426/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1186 - accuracy: 0.9533 - val_loss: 0.2686 - val_accuracy: 0.8810\n",
      "Epoch 427/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1186 - accuracy: 0.9535 - val_loss: 0.2687 - val_accuracy: 0.8810\n",
      "Epoch 428/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1185 - accuracy: 0.9535 - val_loss: 0.2685 - val_accuracy: 0.8810\n",
      "Epoch 429/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1184 - accuracy: 0.9538 - val_loss: 0.2686 - val_accuracy: 0.8810\n",
      "Epoch 430/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1185 - accuracy: 0.9533 - val_loss: 0.2686 - val_accuracy: 0.8810\n",
      "Epoch 431/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1183 - accuracy: 0.9535 - val_loss: 0.2684 - val_accuracy: 0.8810\n",
      "Epoch 432/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1184 - accuracy: 0.9535 - val_loss: 0.2686 - val_accuracy: 0.8810\n",
      "Epoch 433/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1183 - accuracy: 0.9535 - val_loss: 0.2686 - val_accuracy: 0.8810\n",
      "Epoch 434/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1182 - accuracy: 0.9540 - val_loss: 0.2687 - val_accuracy: 0.8810\n",
      "Epoch 435/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1182 - accuracy: 0.9538 - val_loss: 0.2686 - val_accuracy: 0.8810\n",
      "Epoch 436/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1181 - accuracy: 0.9540 - val_loss: 0.2685 - val_accuracy: 0.8810\n",
      "Epoch 437/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1181 - accuracy: 0.9540 - val_loss: 0.2686 - val_accuracy: 0.8810\n",
      "Epoch 438/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1181 - accuracy: 0.9538 - val_loss: 0.2686 - val_accuracy: 0.8810\n",
      "Epoch 439/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1180 - accuracy: 0.9538 - val_loss: 0.2685 - val_accuracy: 0.8810\n",
      "Epoch 440/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1179 - accuracy: 0.9535 - val_loss: 0.2685 - val_accuracy: 0.8810\n",
      "Epoch 441/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1180 - accuracy: 0.9542 - val_loss: 0.2685 - val_accuracy: 0.8810\n",
      "Epoch 442/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1178 - accuracy: 0.9540 - val_loss: 0.2687 - val_accuracy: 0.8810\n",
      "Epoch 443/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1178 - accuracy: 0.9538 - val_loss: 0.2686 - val_accuracy: 0.8810\n",
      "Epoch 444/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1177 - accuracy: 0.9538 - val_loss: 0.2685 - val_accuracy: 0.8796\n",
      "Epoch 445/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1176 - accuracy: 0.9535 - val_loss: 0.2686 - val_accuracy: 0.8810\n",
      "Epoch 446/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1176 - accuracy: 0.9540 - val_loss: 0.2686 - val_accuracy: 0.8796\n",
      "Epoch 447/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1176 - accuracy: 0.9538 - val_loss: 0.2685 - val_accuracy: 0.8796\n",
      "Epoch 448/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1175 - accuracy: 0.9538 - val_loss: 0.2686 - val_accuracy: 0.8796\n",
      "Epoch 449/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1175 - accuracy: 0.9538 - val_loss: 0.2686 - val_accuracy: 0.8796\n",
      "Epoch 450/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1175 - accuracy: 0.9538 - val_loss: 0.2686 - val_accuracy: 0.8796\n",
      "Epoch 451/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1174 - accuracy: 0.9540 - val_loss: 0.2686 - val_accuracy: 0.8796\n",
      "Epoch 452/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1173 - accuracy: 0.9545 - val_loss: 0.2686 - val_accuracy: 0.8796\n",
      "Epoch 453/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1173 - accuracy: 0.9538 - val_loss: 0.2687 - val_accuracy: 0.8796\n",
      "Epoch 454/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1173 - accuracy: 0.9542 - val_loss: 0.2685 - val_accuracy: 0.8796\n",
      "Epoch 455/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1172 - accuracy: 0.9542 - val_loss: 0.2686 - val_accuracy: 0.8796\n",
      "Epoch 456/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1171 - accuracy: 0.9540 - val_loss: 0.2685 - val_accuracy: 0.8796\n",
      "Epoch 457/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1171 - accuracy: 0.9547 - val_loss: 0.2686 - val_accuracy: 0.8810\n",
      "Epoch 458/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1170 - accuracy: 0.9542 - val_loss: 0.2685 - val_accuracy: 0.8796\n",
      "Epoch 459/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1170 - accuracy: 0.9542 - val_loss: 0.2685 - val_accuracy: 0.8810\n",
      "Epoch 460/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1169 - accuracy: 0.9542 - val_loss: 0.2684 - val_accuracy: 0.8796\n",
      "Epoch 461/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1168 - accuracy: 0.9540 - val_loss: 0.2685 - val_accuracy: 0.8810\n",
      "Epoch 462/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1168 - accuracy: 0.9540 - val_loss: 0.2685 - val_accuracy: 0.8810\n",
      "Epoch 463/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1168 - accuracy: 0.9547 - val_loss: 0.2685 - val_accuracy: 0.8810\n",
      "Epoch 464/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1167 - accuracy: 0.9545 - val_loss: 0.2684 - val_accuracy: 0.8810\n",
      "Epoch 465/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1166 - accuracy: 0.9540 - val_loss: 0.2683 - val_accuracy: 0.8810\n",
      "Epoch 466/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1167 - accuracy: 0.9542 - val_loss: 0.2684 - val_accuracy: 0.8810\n",
      "Epoch 467/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1165 - accuracy: 0.9542 - val_loss: 0.2684 - val_accuracy: 0.8810\n",
      "Epoch 468/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1165 - accuracy: 0.9545 - val_loss: 0.2683 - val_accuracy: 0.8810\n",
      "Epoch 469/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1164 - accuracy: 0.9545 - val_loss: 0.2685 - val_accuracy: 0.8810\n",
      "Epoch 470/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1163 - accuracy: 0.9545 - val_loss: 0.2683 - val_accuracy: 0.8810\n",
      "Epoch 471/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1163 - accuracy: 0.9542 - val_loss: 0.2685 - val_accuracy: 0.8810\n",
      "Epoch 472/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1163 - accuracy: 0.9547 - val_loss: 0.2685 - val_accuracy: 0.8810\n",
      "Epoch 473/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1163 - accuracy: 0.9542 - val_loss: 0.2686 - val_accuracy: 0.8810\n",
      "Epoch 474/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1162 - accuracy: 0.9542 - val_loss: 0.2685 - val_accuracy: 0.8810\n",
      "Epoch 475/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1161 - accuracy: 0.9545 - val_loss: 0.2685 - val_accuracy: 0.8810\n",
      "Epoch 476/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1161 - accuracy: 0.9545 - val_loss: 0.2685 - val_accuracy: 0.8810\n",
      "Epoch 477/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1160 - accuracy: 0.9550 - val_loss: 0.2684 - val_accuracy: 0.8810\n",
      "Epoch 478/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1159 - accuracy: 0.9547 - val_loss: 0.2683 - val_accuracy: 0.8810\n",
      "Epoch 479/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1159 - accuracy: 0.9542 - val_loss: 0.2683 - val_accuracy: 0.8810\n",
      "Epoch 480/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1160 - accuracy: 0.9550 - val_loss: 0.2684 - val_accuracy: 0.8810\n",
      "Epoch 481/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1159 - accuracy: 0.9552 - val_loss: 0.2685 - val_accuracy: 0.8810\n",
      "Epoch 482/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1158 - accuracy: 0.9552 - val_loss: 0.2684 - val_accuracy: 0.8810\n",
      "Epoch 483/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1158 - accuracy: 0.9552 - val_loss: 0.2683 - val_accuracy: 0.8810\n",
      "Epoch 484/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1157 - accuracy: 0.9550 - val_loss: 0.2684 - val_accuracy: 0.8810\n",
      "Epoch 485/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1157 - accuracy: 0.9547 - val_loss: 0.2684 - val_accuracy: 0.8810\n",
      "Epoch 486/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1156 - accuracy: 0.9547 - val_loss: 0.2684 - val_accuracy: 0.8810\n",
      "Epoch 487/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1156 - accuracy: 0.9547 - val_loss: 0.2683 - val_accuracy: 0.8810\n",
      "Epoch 488/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1155 - accuracy: 0.9545 - val_loss: 0.2685 - val_accuracy: 0.8810\n",
      "Epoch 489/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1155 - accuracy: 0.9547 - val_loss: 0.2684 - val_accuracy: 0.8810\n",
      "Epoch 490/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1154 - accuracy: 0.9550 - val_loss: 0.2684 - val_accuracy: 0.8810\n",
      "Epoch 491/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1154 - accuracy: 0.9552 - val_loss: 0.2683 - val_accuracy: 0.8810\n",
      "Epoch 492/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1153 - accuracy: 0.9550 - val_loss: 0.2684 - val_accuracy: 0.8810\n",
      "Epoch 493/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1153 - accuracy: 0.9550 - val_loss: 0.2683 - val_accuracy: 0.8810\n",
      "Epoch 494/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1152 - accuracy: 0.9557 - val_loss: 0.2684 - val_accuracy: 0.8810\n",
      "Epoch 495/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1152 - accuracy: 0.9547 - val_loss: 0.2684 - val_accuracy: 0.8810\n",
      "Epoch 496/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1152 - accuracy: 0.9554 - val_loss: 0.2685 - val_accuracy: 0.8810\n",
      "Epoch 497/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1151 - accuracy: 0.9554 - val_loss: 0.2684 - val_accuracy: 0.8810\n",
      "Epoch 498/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1150 - accuracy: 0.9554 - val_loss: 0.2684 - val_accuracy: 0.8810\n",
      "Epoch 499/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1150 - accuracy: 0.9552 - val_loss: 0.2684 - val_accuracy: 0.8810\n",
      "Epoch 500/500\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1150 - accuracy: 0.9547 - val_loss: 0.2684 - val_accuracy: 0.8810\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(history.history.keys())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "plt.plot(history.history['accuracy'])\r\n",
    "plt.plot(history.history['val_accuracy'])\r\n",
    "plt.title('Model Accuracy')\r\n",
    "plt.ylabel('accuracy')\r\n",
    "plt.xlabel('epoch')\r\n",
    "plt.legend(['train', 'validation'])\r\n",
    "plt.grid()\r\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "plt.plot(history.history['loss'])\r\n",
    "plt.plot(history.history['val_loss'])\r\n",
    "plt.title('model loss')\r\n",
    "plt.ylabel('loss')\r\n",
    "plt.xlabel('epoch')\r\n",
    "plt.legend(['train', 'validation'], loc='upper left')\r\n",
    "plt.grid()\r\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_wav_data = load_wav_16k_mono('outdoor_test.wav')\r\n",
    "_, embeddings, _ = yamnet_model(test_wav_data)\r\n",
    "result = speech_model(embeddings).numpy()\r\n",
    "print(result)\r\n",
    "index = result.mean(axis=0).argmax()\r\n",
    "inferred_class = my_classes[result.mean(axis=0).argmax()]\r\n",
    "print(index)\r\n",
    "print(f'The main sound is: {inferred_class}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Using the trained model, create a new model\r\n",
    "Attach the classifier layer trained previously to the YAMNet model and save the model so that it can be loaded for future use. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "saved_model_path = './my_models'\r\n",
    "\r\n",
    "input_layer = tf.keras.layers.Input(shape=(), dtype=tf.float32, name='audio') # WAV audio as input\r\n",
    "# import the YAMNet model from TF Hub\r\n",
    "embedding_extraction_layer = hub.KerasLayer(yamnet_model_handle, \r\n",
    "                                            trainable=False, name='yamnet') \r\n",
    "_, embeddings_output, _ = embedding_extraction_layer(input_layer) # extract embeddings (suppress the classification, mel_spectrogram output of YAMNet)\r\n",
    "model_outputs = speech_model(embeddings_output) # embeddings to my model, to get binary classfier\r\n",
    "#serving_outputs = ReduceMeanLayer(axis=0, name='speechDetector')(serving_outputs)\r\n",
    "model_outputs = tf.argmax(model_outputs, axis=1)\r\n",
    "export_model = tf.keras.Model(input_layer, model_outputs) \r\n",
    "export_model.save(saved_model_path, include_optimizer=False)\r\n",
    "\r\n",
    "tf.keras.utils.plot_model(export_model)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Assets written to: ./my_models\\assets\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:Assets written to: ./my_models\\assets\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing the serving model "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "load_serving = tf.saved_model.load(saved_model_path)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "test_wav_data = load_wav_16k_mono('outdoor_test.wav')\r\n",
    "result = load_serving(test_wav_data)\r\n",
    "print(result)\r\n",
    "# inferred_class = my_classes[tf.argmax(result)]\r\n",
    "# print(f'The main sound is: {inferred_class}')\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'load_serving' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-29415ee80fac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtest_wav_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_wav_16k_mono\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'outdoor_test.wav'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_serving\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_wav_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# inferred_class = my_classes[tf.argmax(result)]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# print(f'The main sound is: {inferred_class}')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_serving' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(tf.argmax(result, axis=1))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "serving_results = load_serving.signatures['serving_default'](test_wav_data)\r\n",
    "inferred_class = my_classes[tf.argmax(serving_results['speechDetector'])]\r\n",
    "print(f'The main sound is: {inferred_class}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "test_wav_data = load_wav_16k_mono('outdoor_test.wav')\r\n",
    "yo1, yo2, yo3 = yamnet_model(test_wav_data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "print(yo1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(\n",
      "[[5.0176477e-01 4.7695935e-03 1.2601018e-03 ... 2.2667646e-04\n",
      "  2.9888749e-04 1.1228919e-03]\n",
      " [2.1172166e-03 6.1533041e-07 4.8989318e-07 ... 1.7276406e-04\n",
      "  9.7787510e-05 3.0747443e-02]\n",
      " [7.9616451e-01 8.7964581e-05 1.4439225e-04 ... 2.8455257e-04\n",
      "  2.2631884e-04 1.4704466e-03]\n",
      " [5.9369999e-01 3.9324164e-04 1.0082016e-04 ... 5.5614114e-04\n",
      "  5.5107474e-04 7.3668361e-04]\n",
      " [8.4982014e-01 2.7152896e-04 4.3946213e-05 ... 3.4129094e-05\n",
      "  7.5790085e-05 2.4475921e-05]], shape=(5, 521), dtype=float32)\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.1",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit"
  },
  "interpreter": {
   "hash": "f590536598b249c76a56afcc0e4a9525a2a7168e83143d1960f7065c3e4f0ea7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}